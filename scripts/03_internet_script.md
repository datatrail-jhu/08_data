In the introductory lesson, we mentioned that there is a lot of data on the Internet, which probably comes at no surprise given the vast amount of information on the Internet. Sometimes these data are in a nice CSV format that we can quickly pull from the Internet. Sometimes, the data are spread across a web page, and it's our job to "scrape"" that information from the webpage and get it into a usable format. Knowing first that this is possible within R and second, having some idea of where to start is an important start to beginning to get data from the Internet. We'll walk through three R packages in this lesson to help get you started in getting data from the Internet. So, before we jump in, we'll have you install the three packages: h t t r, r vest, and j son lite.

In the first lesson we mentioned that Application Programming Interfaces, or APIs, are, in the most general sense, software that allow to different web-based applications to communicate with one another over the Internet. Modern APIs conform to a number of standards. This means that many different applications are using the same approach, so a single package in R is able to take advantage of this and communicate with many different applications, as long as the application's API adheres to this generally agreed upon set of "rules". 

The R package that we'll be using to acquire data and take advantage of this is called h t t r. This package name suggests that this is an "R" package for "H T T P". So, we know what R is, but what about H T T P? 

You've probably seeing H T T P before at the start of web addresses, so you may have some intuition that H T T P has something to do with the Internet, which is absolutely correct! H T T P stands for Hypertest Transfer Protocol. In the broadest sense, H T T P transactions allow for messages to be sent between two points on the Internet. 

You, on your computer can request something from a web page, and the protocol (H T T P) allows you to connect with that webpage's server, do something, and then return you whatever it is you asked for. Working with a web API is similar to accessing a website in many ways. When you type a URL into your browser, information is sent from your computer to your browser. Your browser then interprets what you're asking for and displays the website you've requested. 

Web APIs work similarly. You request some information from the API and the API sends back a response. The h t t r package will hep you carry out these types of requests within R. H T T P is based on a number of important verbs : GET, HEAD, PATCH, PUT, DELETE and POST. For the purposes of retrieving data from the Internet, you may be able to guess which verb will be the most important for our purposes! GET will allow us to fetch a resource that already exists. We'll specify a URL to tell GET where to go look for what we want. We'll only highlight GET in this lesson. GET will access the A P I, provide the API with the necessary information to request the data we want, and retrieve some output. 

The example is based on a wonderful blogpost from Tyler Clavelle at https://www.tylerclavelle.com/code/2017/randapis/. In this example, we'll use will take advantage of Git Hub's A P I, because it's accessible to anyone. Other APIs, while often freely-accessible, require credentials, called an API key. We'll talk about those later, but let's just get started using Git Hub's API now!

The URL you're requesting information from is known as the API endpoint. The documentation from Git Hub's API explains what information can be obtained from their API endpoint: https://api.Git Hub.com. That's the base endpoint, but if you wanted to access a particular individual's Git Hub repositories, you would want to modify this base endpoint to: https://api.Git Hub.com/users/username/repos, where you would replace username with your Git Hub username. Now that we know what our API endpoint is, we're ready to make our API request using GET. The goal of this request is to obtain information about what repositories are available in your Git Hub account. To use the example here, you'll want to change the username jane everyday doe to your Git Hub username. Note that In the code above, you see the function paste zero. This function concatenates, or links together, each the pieces within the parentheses, where each piece is separated by a comma. This provides GET with the URL we want to use as our endpoints! 

Let's first take a look at what other variables are available within the A P I_response object: While we see ten different variables within API underscore response, we should probably first make sure that the request to Git Hub's API was successful. 

We can do this by checking the status code of the request, where "200" means that everything worked properly. But, to be honest, we aren't really interested in just knowing the request worked. We actually want to see what information is contained on our Git Hub account. To do so we'll take advantage of h t t r's content function, which as its name suggests, extracts the contents from an API request.

You can see here that the length of repo_content in our case is 6. This is because the Git Hub account jane everyday doe had six repositories at the time of this API call. We can get some information about each repo by running the function in the code here. Here, we've pulled out the name and URL of each repository in Jane Doe's account; however, there is a lot more information in the repo underscore content object, and we've only pulled out a few pieces. To see how to extract more information, check out the rest of Tyler's full post.

In a previous course in this Course Set on Data Visualization, we assigned a project where the data for the project had already been saved on R Studio Cloud for you in C S V format. However, these data are available on the Internet. Now that we know how to use h t t r and have an understanding about APIs, let's do that now! The data used in that project are available for download from data dot five thirty eight dot com, 

but the data are also hosted on Git Hub. We will refer to a specific link on Git Hub for our GET request.

To obtain this C S V using h t t r, we would use the code you see here. Here, as in the earlier example, we specify our url within GET followed by use of the helpful content function from h t t r to obtain the CSV from the API underscore response object. df underscore steak includes the data from the C S V directly from the Git Hub A P I, without having to download the data first!

Not all A P I's are as "open" as Git Hub's. For example, if you ran the code for the first example above exactly as it was written and didn't change the Git Hub username, you would have gotten information about the repos in jane everyday doe's Git Hub account. Because it is a fully-open A P I, you're able to retrieve information about not only your Git Hub account, but also other users' public Git Hub activity. This makes good sense because sharing code among public repositories is an important part of Git Hub. Alternatively, while Google also has an API (or rather, many A P I's), they aren't quite as open. This makes good sense. There is no reason I should have access to the files on someone else's Google Drive account. Controlling whose files one can access through Google's API is an important privacy feature. In these cases, what is known as a key is required to gain access to the A P I. API keys are obtained from the website's API site. Once acquired, these keys should never be shared on the Internet. There is a reason they're required, after all. So, be sure to never push a key to Git Hub or share it publicly. If you do ever accidentally share a key on the Internet, return to the API and disable the key immediately. For example, to access the Twitter A P I, you would obtain your key and necessary tokens from Twitter's API at https://developer.twitter.com/en/docs/tweets/search/overview and replace the text in the key, secret, token and token underscore secret arguments code you see here. This would authenticate you to use Twitter's API to acquire information about your home timeline. 

Now that we've walked through two cases of obtaining data using an API and discussed API keys, let's transition a little bit to talking about how to pull pieces of data from a website, when the data aren't in the format that we want them. In the first lesson of this course, we talked about the example of wanting to start a company but not knowing exactly what people you'll need. So, you go to the websites of a bunch of companies similar to the company you start and pull off all the names and titles of the people working there. You then compare the titles across companies and voila, you've got a better idea of who you'll need at your new company. You could imagine that while this information may be helpful to have, getting it manually would be a pain. Navigating to each site individually, finding the information, copying and pasting each name. That sounds awful! Thankfully, there's a way to scrape the web from R directly!

This uses the helpful package r vest. It gets its name from the word "harvest." The idea here is you'll use this package to "harvest" information from websites! However, as you may imagine, this is less straightforward than pulling data that are already formatted the way you want them (as we did above), since we'll have to do some extra work to get everything in order. 

When r vest is given a webpage U R L as input, an r vest function reads in the h t m l code from the webpage. h t m l is the language websites use to display everything you see on the website. You've seen h t m l documents before, as this is one of the formats that you can Knit to from an R Markdown document! Generally, all h t m l documents require each webpage to have a similar structure. This structure is specified by using different tags. For example, a header at the top of your webpage would use a specific tag. Website links would use a different tag. These different tags help to specify how the website should appear. r vest takes advantage of these tags to help you extract the parts of the webpage you're most interested in. So let's see exactly how to do that all of this with an example.

To use r vest, there is a tool that will make your life a lot easier. It's called Selector Gadget. It's a "javascript bookmarklet." What this means for us is that we'll be able to go to a webpage, turn on Selector Gadget, and help figure out how to appropriately specify what components from the webpage we want to extract using r vest. To get started using Selector Gadget, you'll have to enable the Chrome Extension. To enable Selector Gadget, open up the Selector Gadget Chrome Extension from Google Chrome. Click "ADD TO CHROME."

Click "Add extension." 

Selector Gadget's icon will now be visible to the right of the web address bar within Google Chrome. You will click on this to use Selector Gadget in the example below.

Similar to the example above, what if you were interested in knowing all the courses in the Chromebook Data Science Course Set? Sure, you could go to our website at http://jhudatascience.org/chromebookdatascience/curriculum.html and copy and paste each one into a Google Sheet. But, that's not very fun! Alternatively, you could write and run a few lines of code and get all the information that way! We'll do that in the example below. To use Selector Gadget, navigate to the webpage we're interested in scraping and toggle Selector Gadget by clicking on the Selector Gadget icon. A menu at the bottom-right of your web page should appear.

Now that Selector Gadget has been toggled, as you mouse over the page, colored boxes should appear. We'll click on the the name of the first course to start to tell Selector Gadget which component of the webpage we're interested in. A red box will appear around the component of the webpage you've clicked. Other components of the webpage that Selector Gadget has deemed similar to what you've clicked will be highlighted. And, text will show up in the menu at the bottom of the page letting you know what you should use in r vest to specify the part of the webpage you're most interested in extracting. Here, we see with that Selector Gadget has highlighted the course names and nothing else! Perfect. That's just what we wanted. Now we know how to specify this element in r vest!

Now we're ready to use r vest's functions. We'll use read underscore h t m l to read in the h t m l from our webpage of interest. We'll then use h t m l underscore nodes to specify which parts of the webpage we want to extract. Within this function we specify "strong", as that's what Selector Gadget told us to specify to "harvest" the information we're interested in. Finally h t m l underscore text extracts the text from the tag we've specified, giving us that list of courses we wanted to see!

With just a few lines of code we have the information we were looking for!

Selector Gadget selected what we were interested in on the first click in the example above. However, there will be times when it makes its guess and highlights more than what you want to extract. In those cases, after the initial click, click on any one of the items currently highlighted that you don't want included in your selection. Selector Gadget will mark that part of the webpage in red and update the menu at the bottom with the appropriate text.

In talking about APIs and API request calls, we left out a tiny bit of information. API requests generally return data in one of two data formats: J SON or X M L. We'll discuss a bit more about each these data formats in future lessons. However, as this is a lesson about obtaining information from the Internet, we'd be remiss not to mention that there are ways to work with J SON data in R, using the package j son lite. Very briefly here, J SON  stands for JavaScript Object Notation and is a text-based way to send information between a browser and a server. J SON is easy for humans to read and to write. Thus, it makes sense that API calls would return information in the J SON format. J SON data adhere to certain rules in how they are structured. For simplicity, J SON format requires objects to be comprised of key-value pairs. For example, here "Name" is a key, and "Isabela" is a value. Together, they are a key-value pair. Let's take a look at how J SON data looks in R. 

This format cannot, as it is, be easily worked with within R; however, there is an R package to take data from J SON format to an object-based format, that can be worked with in R. The R package J SON lite is just what to work with whenever you have data in J SON format. 

When using the defaults of the function from J SON, J SON lite will take the data from J SON array format and helpfully return a data frame. 

Data frames can also be returned to their original J SON format using the function: to J SON. Here, we've just briefly touched on what J SON format is; however, in a future lesson we'll discuss this in greater detail. For now, however, it's important to know that the J SON lite package is there for you whenever you have J SON data. And, it has two very helpful functions (among other functions in the package!): to J SON and from J SON for such situations.

So far, we've discussed how to work with data you've obtained from the Internet. However, things on the Internet can change. If you're not downloading the file to your system directly, you won't have a static copy saved on your system. This means that while you're saving space on your computer and not creating unnecessary copies of an identical file, the next time you go to access the file, it may not be there or it may have been updated. For these reasons, it's incredibly important to record the date of when you acquired the data. This can be recorded in your R Markdown file where you're doing your analysis or your data science lab notebook (to be discussed in a later lesson). Regardless, however, a record of the date you acquired the data is incredibly important.