Up to this point in the course set, we've primarily worked with data in a tidy spreadsheet format. Whether this was data that we had to wrangle to get into that format or data stored in a database already in a tidy format, it was tidy nonetheless. It's important, however, to know that data do not always come in a spreadsheet-friendly format. While as a data scientist you will often be working with data stored in spreadsheets, you'll also likely work with some unconventional types of data. 

So far, we have primarily focused on structured data. Structured Data are data that have a high degree of organization. Tidy spreadsheets where the data can be easily analyzed using the data wrangling and visualization skills discussed so far in this course set are an example of structured data. Unstructured data, on the other hand, are data that are not organized in a pre-defined manner. These data do not fit into rows and columns in a spreadsheet. Unstructured data may contain text, images, audio files, and even video files. Given the differences in these types of data, traditional methods for cleaning and analyzing these kind of data are not as helpful. Nevertheless, there are ways to work with these data in R. We'll introduce a number of different types of unstructured data and then give you a brief example of where you would start if you wanted to work with each unconventional data type in R. 

While most of the data we've seen so far has been stored in rows and columns within a spreadsheet, text documents or words of any kind can also be data! Text analytics or text mining is the process of taking large collections of text, generating a dataset from the that can be analyzed, and analyzing the words in that dataset. In other words, text mining is the process of converting textual data from unstructured form to a structured form for analysis or visualization.An application of text mining is sentiment analysis. In sentiment analysis, the goal is to categorize the text and quantify opinions expressed within the text. For instance, in a lot of satisfaction surveys, as you may have taken, the company asks you to express your opinion about your experience or a specific product in a few sentences. Historically, due to the fact that survey respondents could have typed anything they wanted in these boxes, these kind of data were often ignored when analyzing the survey data due to their unstructured nature. In other words, free text responses on a survey can be hard to analyze. In cases where these data were analyzed, the text from each survey respondent would have been read by a human. That human would asses what the response and assign a score as to how positive or negative the text was. However, using sentiment analysis we are now able to read a vast amount of textual data and use an algorithm to assign that value to respondent's attitude toward the service or the product. There are different approaches to sentiment analysis. Sometimes, a paragraph of text will be evaluated to assess how sad or happy the words in the text are. Other times, you'll use sentiment analysis to gauge how positive or negative the words in the text are. Other times still, words will be analyzed using sentiment analysis to determine how scientific or unscientific text is.

While not the most typical type of data analyzed in R, R can be used to analyze text. There are three packages that are particularly helpful for analyzing textual data sing text mining: t m, tidy text, and language R. To see an example of text analysis in R, check out David Robinson's post Text analysis of Trump's tweets confirms he writes only the (angrier) Android half. The link to this post is on the slide; however, briefly here, David Robinson uses the tidy text package, twitteR package, and Twitter A P I to analyze the tweets from Donald Trump during his presidential campaign.

In an earlier lesson in this course we touched on the fact that J SON is a text-based way to send information between a browser and a server and a frequent format in which you'll retrieve data from an A P I call. We also mentioned that J SON format requires objects to be comprised of key-value pairs. For example, in the case you see here, "Name" would be a key, "Isabela" would be a value, and together they would be a key-value pair. 

That's where we left our explanation of J SON data in the earlier lesson. Here we'll use a snippet of J SON data to explain that in addition to using key-pairs J SON data are nested and hierarchical. This means that key-pairs can be organized into different levels (hierarchical) with some levels of information being stored within other levels (nested). Using a snippet of J SON data here, we see a portion of J SON data from Yelp explaining a restaurant. We're looking at the attributes of this restaurant. Within attributes, there are four nested categories: Take-out, Wi-Fi, Drive-Thru, and Good For. In the hierarchy, attributes is at the top, while these four categories are within attributes. Within one of these attributes Good For, we see another level within the hierarchy. In this third level we see a number of other categories nested within Good For. This should give you a slightly better idea of how J SON data are structured.

Above we discussed how to analyze pure text. Here, we'll discuss how to briefly how others have wrangled text-based data from the Internet in the J SON format within R. This is possible because of the R package j son lite, which was used in the example you see here. Here, Kan Nishida], a data scientist, was interested in [understanding what restaurant types found most frequently in each state or province. To do this, he used J SON data orginally released from Yelp. He wrangled the data from J SON format into a tabular format using j son lite and other data wrangling packages, such as d ply r, to ultimately determine the types of restaurants found most frequently in a number of different states and provinces.

Extensible Markup Language, or X M L, is another human- and machine-readable language that is used frequently by web services and A P Is. However, instead of being based on key-value pairs, X M L relies on nodes, tags, and elements. The author defines these tags to specify what information is included in each element of the X M L document and allows for elements to be nested within one another. The nodes define the hierarchical structure of the X M L (which means that X M L is hierarchical and nested like J SON)! X M L accomplishes the same goal as J SON, but it just does it in a different format. Thus, the two formats are used for similar purposes -- sharing information on the web; however, because the format in which they do this is different, a different R package is needed to process X M L data. This packages is called X M L 2.

To see an example of not only using X M L 2 to parse X M L data, but also another example of using rvest to obtain the X M L data, check out this post from Jose Roberto Ayala Solares where he took the text from a New York Times article called Trump's Lies, scraped the data from the web (obtaining it in X M L), and then wrangled it into a tidy format using X M L2. In this lesson, our goal is to make you aware that data from the Internet (and A P Is in particular) will often come in either J SON or X M L format. Thus, the J SON and X M L examples provided here only give you a bit of an idea of what J SON and X M L data are and how to work with them. Nevertheless, the more frequently you retrieve data from A P Is and the Internet, the more comfortable you'll have to become with both J SON and X M L. And, J son lite and X M L 2 will help you as you work with these data in R!

Only a few decades ago, analyzing a large dataset of images was not feasible for most researchers. Many didn't even think of images as data. But, there is so much we can get from analyzing image data. Although we will not study images processing techniques in this lesson, let's look at one example that give us an idea of how image data can be used. Within Google Maps there is a Street View feature that allows panoramic views from positions along many streets in the world. One of the things you may notice if you're looking around on Google Maps' street view is that for many streets in the world you do not only see houses; you are also able to see cars. 

Some 50 million images of cars from over 200 cities were used by researchers to detect the make, model, body type, and age of the cars in each neighborhood. They were able to take unstructured image data and compile a structured data set! These same researchers then pulled together a structured dataset from the Census and the 2008 elections of demographic information (such as race and income), and voting history in these same neighborhoods. 

Using these two datasets (the Google Street view car image data and the demographic data), researchers used a technique known as machine learning to build an algorithm that could, from the images of cars in a neighborhood, predict the demographics (race, income, etc) and how that area is likely to vote. Comparing these two sets of data, they were able to accurately estimate income, race, education, and voting patterns at the zip code level from the Google Street view images.

Like with text, there are packages in R that will help you carry out analysis of images. In particular, magick is particularly helpful for advanced image processing within R, allowing you to process, edit, and manipulate images within R. Like J SON and X M L, where there is more than one file format for a similar task, there are also a number of different image file formats. We touched on the pros and cons of a number of these in the Data Visualization course; however, of importance here is the fact that the magick package is capable of working with many different types of images, including P N G, J PEG, and TIFF. The magick package has a particularly helpful vignette where you can learn the ins and outs of working with images using magick's functionality. Their documentation will discuss how to read image data into R, how to edit images, and even how to add images to your R plots! 

So much of the data generated today comes in the form of audio files. This could be all the data contained within the MP3 files of your favorite songs or the audio files saved in the archives from the speeches of politicians. While certainly not tabular data, there is a lot of information stored within all the audio files we've generated! It likely isn't surprising that there are many different file types to store audio data. M P 3s are currently the most common file format, becoming popular as CDs became less popular due to the fact that the same audio file saved as an M P 3 would take up much less space than the same file stored on a C D. However, if working with audio files, one would want to learn much more about how audio files are stored in different file formats.

There are two packages that will likely be helpful for analyzing audio files in R: tune R and see wave. Admittedly, working with audio files in R is not as common as working with tabular data; however, that just means there's room for development and exploration of how to approach audio files in R. To see how others have worked with audio files in R, take a look through the example link here where an R user looked to cluster his mucic using the tune R and see wave packages.

In this lesson, we've briefly reviewed a number of different unconventional sources of data. These are data sources that are unstructured and not tabular. We've provided examples for each type of unconventional data and links to where you may start if you wanted to work with each type of data in R. This lesson is an introduction into these types of data, but is by no means exhaustive.